# 计算机网络

> 主要分成三个大部分，一是课上学的整体框架知识，二是HTTP协议，三是TCP/UDP/IP

## 网络分层模型

> 网络本身是复杂的，为了实现/维护的简单方便。像程序有常见的架构一样，网络也有分层协议

### 基本的五层协议

1. 应用层：为应用程序间提供数据传输服务，数据单位是报文
2. 传输层：为进程间提供通用数据传输服务，数据单位为报文段
3. 网络层：为分组交换网络上的不同主机提供数据传输服务，数据单位是数据报
4. 数据链路层：为同一链路的主机提供数据传输服务，数据单位是帧
5. 物理层：在物理层面（传输媒体/介质）上传输数据，数据单位是bit

### OSI七层模型

OSI七层模型对应用层进行了进一步的拆分，拆分太多反而有一些不太实用

![img](笔记.assets\osi-model-detail.png)

### TCP/IP模型

只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。

TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。

### 应用层常见协议

#### HTTP协议

超文本传输协议，基于TCP协议，主要为Web服务器间通信而设计

HTTP是无状态的协议，无法记录客户端用户的状态，一般通过Session记录客户端用户的状态

#### SMTP协议

简单邮件传输(发送)协议，基于TCP协议，用来发送电子邮件

#### POP3/IMAP协议

邮件接收的协议，IMAP相较于POP3有一点点更新

#### FTP协议

文件传输协议，基于TCP实现可靠传输，传输文件可以屏蔽操作系统和文件存储方式。

其特点在于使用两条TCP连接，命令和数据分开传送，效率很高

1. 控制连接：用于传送控制信息（命令和响应）
2. 数据连接：用于数据传送；

#### Telnet协议

远程登陆协议，基于TCP实现，但是明文发送数据，不安全

#### SSH协议

安全的网络传输协议，基于TCP实现，是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议

与Telnet的主要区别在于会对传输的数据进行加密

## HTTP/HTTPS

> Http协议是规范浏览器和服务器端行为的协议
>
> 其优点在于：**扩展性强、速度快、跨平台支持性好**

### HTTP/HTTPS协议简介

#### HTTP协议的通信过程

1. 服务器在 80 端口等待客户的请求。
2. 浏览器发起到服务器的 TCP 连接（创建套接字 Socket）。
3. 服务器接收来自浏览器的 TCP 连接。（如果是HTTPS将有加解密）
4. 浏览器（HTTP 客户端）与 Web 服务器（HTTP 服务器）交换 HTTP 消息。
5. 关闭 TCP 连接。

#### HTTPS/HTTP协议的区别

HTTPS 协议（Hyper Text Transfer Protocol Secure），是 HTTP 的加强安全版本。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并额外使用 SSL/TLS 协议用作加密和安全认证。默认端口号是 443

### SSL/TLS协议

#### SSL/TLS协议的区别

TLS协议是基于SSL之上的协议：SSL3.0 = TLS 1.0

#### SSL/TLS的工作原理

1. 非对称加密：公钥加密、私钥解密。比较出名的算法有RSA

	> **非对称加密核心技术**：单向陷门函数，一个较弱的单向函数。已知单向陷门函数 f，陷门 h，给定任意一个输入 x，易计算出输出 y=f(x;h)；而给定一个输出 y，假设存在 f(x;h)=y，很难根据 f 来计算出 x，但可以根据 f 和 h 来推导出 x。

2. 数字签名/证书：主要有两个步骤，一是对需要发送的数据进行信息摘要（一般是对数据内容进行哈希得到的**哈希值**），二是对摘要信息进行私钥加密。在HTTPS协议中，第三方信赖机构，简称CA会用私钥对需要认证的公钥及相关的信息进行加密

#### HTTPS协议的工作流程

在HTTP协议基础上，加入一些额外的流程

1. 客户端向服务端发起请求

	1. 客户端生成随机数R1
	2.  发送给服务端告诉服务端自己支持哪些加密算法和哈希算法

2. 服务器向客户端发送数字证书

	1. 服务端生成随机数R2
	2. 从客户端支持的加密算法中选择一种双方都支持的加密算法（此算法用于后面的会话密钥生成）和哈希算法。用机构的证书公钥解密得到证书的内容和证书签名。最后把证书、随机数R2、会话密钥生成算法，一同发给客户端

3. 客户端验证数字证书。 

	这一部分是**浏览器内置的 TSL** 完成的：

	1. 首先浏览器会从内置的证书列表中索引，找到服务器下发证书对应的机构，如果没有找到，此时就会提示用户该证书是不是由权威机构颁发，是不可信任的。如果查到了对应的机构，则取出该机构颁发的公钥、会话密钥生成算法、随机数R2。
	2.  用机构的证书公钥解密得到证书的内容和证书签名，内容包括网站的网址、网站的公钥、证书的有效期等。浏览器会先验证证书签名的合法性。签名通过后，浏览器验证证书记录的网址是否和当前网址是一致的，不一致会提示用户。如果网址一致会检查证书有效期，证书过期了也会提示用户。这些都通过认证时，浏览器就可以安全使用证书中的网站公钥了。
	3. 浏览器生成一个随机数 R3，根据会话密钥算法使用R1、R2、R3生成会话密钥。
	4.  用服务端证书的公钥加密随机数R3并发送给服务端。

	> 注意：以上其实就是 HTTPS 的握手过程，这个过程主要是认证服务端证书（内置的公钥）的合法性。因为非对称加密计算量较大，整个通信过程只会用到一次非对称加密算法（主要是用来保护传输客户端生成的用于对称加密的随机数私钥）。后续内容的加解密都是通过一开始约定好的对称加密算法进行的。

4. 服务器得到会话密钥

	1. 服务器用私钥解密客户端发过来的随机数R3
	2. 根据会话密钥算法使用R1、R2、R3生成会话密钥

5. 客户端与服务端进行加密会话

	1. 客户端发送加密数据给服务端

		发送加密数据：客户端加密数据后发送给服务端。

	2. 服务端响应客户端

		解密接收数据：服务端用会话密钥解密客户端发送的数据

		加密响应数据：用会话密钥把响应的数据加密发送给客户端。客户端解密服务端响应的数据

	解密数据：客户端用会话密钥解密响应数据

![img](C:\Users\yato\Desktop\U know wt\interviewPre\dailyNote\笔记.assets\HTTPS工作流程.png)

用简单的话来说就是

1. CA颁发附有消息摘要加密签名的证书发送给服务端，服务端附上密钥生成算法和原始的值后发送给客户端
2. 客户端收到后进行验证，如果合法就生成私钥并用证书中公钥加密，发送给服务器
3. 服务器收到后用私钥加密内容发送给客户端

### HTTP 1.0 VS HTTP 1.1

#### 响应状态码

HTTP 1.1 新增大量响应状态码，比如状态码100——请求大资源前的预热

#### 缓存处理

先谈谈HTTP的缓存机制

服务器端使用`Expires`标签来标志（时间）一个响应体，在`Expires`标志时间内的请求，都会获得该响应体缓存。服务器端在初次返回给客户端的响应体中，有一个`Last-Modified`标签，该标签标记了被请求资源在服务器端的最后一次修改。在请求头中，使用`If-Modified-Since`标签，该标签标志一个时间，意为客户端向服务器进行问询：“该时间之后，我要请求的资源是否有被修改过？”通常情况下，请求头中的`If-Modified-Since`的值即为上一次获得该资源时，响应体中的`Last-Modified`的值。

如果服务器接收到了请求头，并判断`If-Modified-Since`时间后，资源确实没有修改过，则返回给客户端一个`304 not modified`响应头，表示”缓冲可用，你从浏览器里拿吧！”。

如果服务器判断`If-Modified-Since`时间后，资源被修改过，则返回给客户端一个`200 OK`的响应体，并附带全新的资源内容，表示”你要的我已经改过的，给你一份新的”。

> 简单来说就是会记录上次修改的时间，如果上次获得资源到现在重新申请这段时间都没改过，就可以从缓存中拿

HTTP 1.1在原理不变的基础上，增加很多特性

#### 连接方式

这个很出名。1.0默认短连接，即任务结束就中断连接。这样每次申请一个其他Web资源都会重新建立连接，浪费很多资源。

1.1默认长连接，可以持久提供数据交互服务。However，一直开着连接也不是个事，所以有的服务器支持超时判断

实际上就是TCP的长连接、短连接

#### Host头处理

1.0发送请求不会加入主机名，而DNS又会将多个主机名绑定在同一个IP地址上的情况。1.1的请求报文将Host字段(主机名)一并发送给服务端，服务端将可以得知请求的真正网址

#### 带宽优化

1.1主要从三点出发进行优化

1. 是引入请求一个文件的一部分，或继续下载之前未完成的文件的功能。

	> HTTP/1.1可以在请求中加入`Range`头部，以请求（并只能请求字节型数据）数据的一部分。服务器端可以忽略`Range`头部，也可以返回若干`Range`响应。
	>
	> 如果一个响应包含部分数据的话，那么将带有`206 (Partial Content)`状态码。该状态码的意义在于避免了HTTP/1.0代理缓存错误地把该响应认为是一个完整的数据响应，从而把他当作为一个请求的响应缓存。

2. 引入状态码100，大资源请求来之前可以进行预热

3. 对内容编码、传输编码做区分，实现端到端压缩和逐跳压缩

### HTTP常见状态码

>HTTP 状态码用于描述 HTTP 请求的结果

#### 1xx informational（信息性状态码）

表示接收的请求正在处理

#### 2xx success（成功状态码）

表示请求正常处理完毕

- **200 OK** ：请求被成功处理。比如我们发送一个查询用户数据的HTTP 请求到服务端，服务端正确返回了用户数据。这个是我们平时最常见的一个 HTTP 状态码。
- **201 Created** ：请求被成功处理并且在服务端创建了一个新的资源。比如我们通过 POST 请求创建一个新的用户。
- **202 Accepted** ：服务端已经接收到了请求，但是还未处理。
- **204 No Content** ： 服务端已经成功处理了请求，但是没有返回任何内容。（请求的时候就没要求返回，只要处理结果成功就行）

#### 3xx redirection（重定向状态码）

表示需要进行附加操作以完成请求

- **301 Moved Permanently** ： 资源被永久重定向了。比如你的网站的网址更换了。
- **302 Found** ：资源被临时重定向了。比如你的网站的某些资源被暂时转移到另外一个网址。

#### 4xx client error（客户端错误状态码）

表示服务器无法处理请求

- **400 Bad Request** ： 发送的HTTP请求存在问题。比如请求参数不合法、请求方法错误。
- **401 Unauthorized** ： 未认证却请求需要认证之后才能访问的资源。
- **403 Forbidden** ：直接拒绝HTTP请求，不处理。一般用来针对非法请求。
- **404 Not Found** ： 你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。
- **409 Conflict** ： 表示请求的资源与服务端当前的状态存在冲突，请求无法被处理。

#### 5xx server error（服务端错误状态码）

表示服务器处理请求出错

- **500 Internal Server Error** ： 服务端出问题了（通常是服务端出Bug了）。比如你服务端处理请求的时候突然抛出异常，但是异常并为在服务端被正确处理。
- **502 Bad Gateway** ：我们的网关将请求转发到服务端，但是服务端返回的却是一个错误的响应。

## TCP/UDP

**同步SYN**：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1。

**终止FIN**：用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。

**确认ACK**：仅当ACK=1,时确认号字段才有效，当ACK=0时，确认号无效。建立连接后ACK应该始终为1

**ack**：占四个字节，是期望收到对方下一个报文段的第一个数据字节的序号

**seq**：占四个字节，是指的是本报文段所发出的数据的第一个字节的序号

### 三次握手/四次挥手

#### 三次握手的过程

- **一次握手**:客户端发送带有 SYN（SEQ=x） 标志的数据包 -> 服务端，然后客户端进入 **SYN_SEND** 状态，等待服务器的确认；

- **二次握手**:服务端发送带有 SYN+ACK(SEQ=y,ACK=x+1) 标志的数据包 –> 客户端,然后服务端进入 **SYN_RECV** 状态

	> 这里叫半连接

- **三次握手**:客户端发送带有带有 ACK(ACK=y+1) 标志的数据包 –> 服务端，然后客户端和服务器端都进入**ESTABLISHED** 状态，完成TCP三次握手

#### 为什么需要三次握手

1. 一次握手是Server确认Client发送正常，自己接收正常
2. 二次握手是Client确认自己发送、接收正常，对方发送接收正常；Server还是只能确认Client发送正常、自己接收正常
3. 三次握手确认双方收发功能都正常

#### 为什么第二次握手会回传SYN

首先介绍一下SYN， 它是TCP/IP 建立连接时使用的握手信号。

使用SYN表示服务端确实收到客户端的信号，建立并确认从服务端到客户端的通信，不传SYN不能表示服务端想建立连接。

#### 四次挥手的过程

1. **第一次挥手** ：客户端发送一个 FIN（SEQ=X） 标志的数据包->服务端，用来关闭客户端到服务器的数据传送。然后，客户端进入 **FIN-WAIT-1** 状态。
2. **第二次挥手** ：服务器收到这个 FIN（SEQ=X） 标志的数据包，它发送一个 ACK （SEQ=X+1）标志的数据包->客户端 。然后，此时服务端进入**CLOSE-WAIT**状态，客户端进入**FIN-WAIT-2**状态。
3. **第三次挥手** ：服务端关闭与客户端的连接并发送一个 FIN (SEQ=y)标志的数据包->客户端请求关闭连接，然后，服务端进入**LAST-ACK**状态。
4. **第四次挥手** ：客户端发送 ACK (SEQ=y+1)标志的数据包->服务端并且进入**TIME-WAIT**状态，服务端在收到 ACK (SEQ=y+1)标志的数据包后进入 CLOSE 状态。此时，如果客户端等待 **2MSL** 后依然没有收到回复，就证明服务端已正常关闭，随后，客户端也可以关闭连接了。

只要四次挥手没有结束，客户端和服务端可以继续传输数据

#### 为什么需要四次挥手

第一次挥手：客户端表示已经没有要发送的数据了，但是还可以接收数据

第二次挥手：服务端表示理解，但是自己的数据还没发送完，要等一等

第三次挥手：服务端表示自己的数据已经发送完了，可以断开连接

第四次挥手：客户端表示合作愉快下次继续，本次连接顺利断开

前三次是容易理解的，无非是要断开连接和确认最后的数据发送完

第四次则是tcp对可靠传输的保证，要求客户端已经收到服务端断开连接的请求，不然服务端放心不下，觉得客户端还在等它传数据

#### 可以三次挥手吗

可以，如果客户端关闭连接时，服务器已经没有要发送的数据，可以将第二次、第三次挥手合并

### 可靠传输

#### TCP如何实现传输的可靠性

1. **基于数据快传输** ：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。
2. **对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。
3. **校验和** : TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. **超时重传** : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为[已丢失open in new window](https://zh.wikipedia.org/wiki/丢包)并进行重传。
5. **流量控制** : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。
6. **拥塞控制** : 当网络拥塞时，减少数据的发送。

#### TCP如何实现流量控制

**流量控制是为了控制发送方发送速率，保证接收方来得及接收。**

TCP通过滑动窗口来实现流量控制

**`发送窗口`**

![TCP发送窗口结构](笔记.assets\tcp-send-window.png)

**`接收窗口`**

![TCP接收窗口结构](笔记.assets\tcp-receive-window.png)

**接收窗口的大小是根据接收端处理数据的速度动态调整的**

#### TCP如何实现拥塞控制

拥塞窗口：TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。**发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。**

三步走战略

1. 慢开始：逐次加倍的扩大拥塞窗口，1-2-4-8
2. 拥塞避免：当到大一个阈值时，就逐次加1的扩大窗口。假设阈值为16，就是16-17-18
3. 快重传/快恢复：如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。

一些细节问题：**阈值不是固定的，一般来说会取峰值的一半。所谓峰值就是发现超时重传现象时的拥塞窗口的大小。当发生重传现象时，拥塞窗口大小变为1，并重新执行慢开始和拥塞避免操作**

#### ARQ协议

> 如果发送方在发送后一段时间之内没有收到确认信息（Acknoledgements，就是我们常说的 ACK），通常会重新发送，直到收到确认或者重试超过一定的次数。

**`停止等待ARQ协议`**

一个分组一个分组的发送、接收消息。

**1) 无差错情况:**

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。

**3) 确认丢失和确认迟到**

- **确认丢失** ：确认消息在传输过程丢失。当 A 发送 M1 消息，B 收到后，B 向 A 发送了一个 M1 确认消息，但却在传输过程中丢失。而 A 并不知道，在超时计时过后，A 重传 M1 消息，B 再次收到该消息后采取以下两点措施：1. 丢弃这个重复的 M1 消息，不向上层交付。 2. 向 A 发送确认消息。（不会认为已经发送过了，就不再发送。A 能重传，就证明 B 的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到。A 发送 M1 消息，B 收到并发送确认。在超时时间内没有收到确认消息，A 重传 M1 消息，B 仍然收到并继续发送确认消息（B 收到了 2 份 M1）。此时 A 收到了 B 第二次发送的确认消息。接着发送其他数据。过了一会，A 收到了 B 第一次发送的对 M1 的确认消息（A 也收到了 2 份确认消息）。处理如下：1. A 收到重复的确认后，直接丢弃。2. B 收到重复的 M1 后，也直接丢弃重复的 M1。

**`连续ARQ协议`**

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，**对按序到达的最后一个分组发送确认**，表明到这个分组为止的所有分组都已经正确收到了。

**二者pk**

1. 前者可以确保分组发送正确，后者由于只对按序到达的最后一个分组发送确认，所以没有收到的分组之后的所有分组都得重传(也称作go-back-n)
2. 前者信道利用率低，后者信道利用率

TCP实际上使用连续ARQ协议和滑动窗口协议

### ARP协议

> 地址解析协议，解决的是网络层地址和链路层地址之间的转换问题。 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 IP 地址属于逻辑地址，而 MAC 地址才是物理地址

是**广播问询，单播响应**的协议

#### MAC地址

媒体访问控制地址，一切网络设备都由 MAC 地址唯一且不可改变的标识

前3个字节由IEEE统一分配管理，后3个字节由生产商自己管理

PS：MAC 地址有一个特殊地址：FF-FF-FF-FF-FF-FF（全 1 地址），该地址表示广播地址

#### ARP表

在一个局域网内，每个网络设备都自己维护了一个 ARP 表，ARP 表记录了某些其他网络设备的 IP 地址-MAC 地址映射关系，该映射关系以 `<IP, MAC, TTL>` 三元组的形式存储。其中，TTL 为该映射关系的生存周期，典型值为 20 分钟，超过该时间，该条目将被丢弃

下面以主机A 向 主机B 发送IP数据报文为例

**同一局域网内**：

1. 主机 A 检索自己的 ARP 表，发现 ARP 表中并无主机 B 的 IP 地址对应的映射条目，也就无从知道主机 B 的 MAC 地址。

2. 主机 A 将构造一个 ARP 查询分组，并将其广播到所在的局域网中。

	ARP 分组是一种特殊报文，ARP 分组有两类，一种是查询分组，另一种是响应分组，它们具有相同的格式，均包含了发送和接收的 IP 地址、发送和接收的 MAC 地址。当然了，查询分组中，发送的 IP 地址，即为主机 A 的 IP 地址，接收的 IP 地址即为主机 B 的 IP 地址，发送的 MAC 地址也是主机 A 的 MAC 地址，但接收的 MAC 地址绝不会是主机 B 的 MAC 地址（因为这正是我们要问询的！），而是一个特殊值——`FF-FF-FF-FF-FF-FF`，之前说过，该 MAC 地址是广播地址，也就是说，查询分组将广播给该局域网内的所有设备。

3. 主机 A 构造的查询分组将在该局域网内广播，理论上，每一个设备都会收到该分组，并检查查询分组的接收 IP 地址是否为自己的 IP 地址，如果是，说明查询分组已经到达了主机 B，否则，该查询分组对当前设备无效，丢弃之。

4. 主机 B 收到了查询分组之后，验证是对自己的问询，接着构造一个 ARP 响应分组，该分组的目的地只有一个——主机 A，发送给主机 A。同时，主机 B 提取查询分组中的 IP 地址和 MAC 地址信息，在自己的 ARP 表中构造一条主机 A 的 IP-MAC 映射记录。

	ARP 响应分组具有和 ARP 查询分组相同的构造，不同的是，发送和接受的 IP 地址恰恰相反，发送的 MAC 地址为发送者本身，目标 MAC 地址为查询分组的发送者，也就是说，ARP 响应分组只有一个目的地，而非广播。

5. 主机 A 终将收到主机 B 的响应分组，提取出该分组中的 IP 地址和 MAC 地址后，构造映射信息，加入到自己的 ARP 表中。

**局域网外**

相较于前者，主机A的目的MAC地址改为**本子网内与路由器连接的接口的 MAC 地址**。主机 A 将把这个链路层帧，以单播的方式，发送给目标接口。

目标接口会转发至主机B对应IP子网，如果ARP表上最好，找不到继续广播

### SYN攻击

> SYN攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包（半连接请求），服务器回复确认包，并等待客户的确认。
>
> 最终导致服务器就无法处理正常连接

#### 检测手段

一般来说如果服务器上有大量半连接状态，并且源IP地址随机，可以任务发生SYN攻击。

#### 防御措施

1. 缩短超时时间

2. 增加最大半连接数

3. 使用syn cookie

	> 服务器在收到syn包时并不马上分配储存连接的数据区，而是根据这个syn包计算出一个cookie，把这个cookie填入tcp的Sequence Number字段发送syn+ack包，等对方回应ack包时检查回复的Acknowledgment Number字段的合法性，如果合法再分配专门的数据区。
	>
	> 也就是一开始不分配存储空间，后面再分配

4. 使用过滤网关，可以走SYN代理

### TCP/UDP的区别

1. 基于连接与无连接：UDP是无连接的，即发送数据之前不需要建立连接
2. TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。
3.  UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。
4.  每一条TCP连接只能是点到点的；UDP支持一对一，一对多，多对一和多对多的交互通信。
5.  TCP对系统资源要求较多，UDP对系统资源要求较少。 

# 操作系统

> **管理计算机硬件与软件资源的程序，计算机的基石**

本质上是一个管理计算机硬件和软件资源的软件程序，其存在屏蔽了硬件层的复杂性。核心部分是内核，负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理

## 概述

### 系统调用

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

系统调用大致分为：进程控制、进程通信、文件操作、设备操作、内存管理

## 进程管理

### 进程状态的切换

![img](笔记.assets\ProcessState.png)

### 进程调度算法

#### 批处理系统

没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）

1. FCFS：先来先服务，按请求的顺序进行调度。可能让短作业等待时间过长
2. SJF：短作业优先，让运行时间最短的进程先执行。可能让长作业饥饿
3. SRTN：最短剩余时间优先：短作业优先的抢占版本

#### 交互式系统

有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

1. 时间片轮转：以FCFS的原则将就绪进程派程一个队列，每次调度会把CPU时间分给队首进程，时间片执行完毕后，将队首进程送到队尾。
2. 优先级调度：为每个进程分配一个优先级，按优先级进行调度
3. 多级反馈队列：一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

### 进程同步

1. 临界区：对临界资源进行访问的那段代码称为临界区。
2. 同步与互斥：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系叫做同步；多个进程在同一时刻只有一个进程能进入临界区叫做互斥
3. 信号量：信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作
4. 管程：引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。进程可以在管程的缓冲区内读取或存储数据

### 进程通信

1. 管道：只支持半双工通信、只能在父子进程或者兄弟进程中使用

2. FIFO：命名管道，去除了管道只能在父子进程中使用的限制

3. 消息队列：FIFO的升级，独立于读写进程存在；避免FIFO的同步阻塞问题；读进程可以根据消息类型有选择地接收消息

4. 信号量：为多个进程提供对共享数据对象的访问

5. 共享存储：允许多个进程共享一个给定的存储区。

	> 需要使用信号量用来同步对共享存储的访问。多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

6. 套接字：可用于不同机器间的进程通信

## 死锁

### 必要条件

1. 互斥：每个资源要么已经分配给了一个进程，要么可用
2. 占有并等待：已经得到某个资源的进程可以请求新的资源
3. 非抢占：已经分配给一个进程的资源不能被强制性的抢占
4. 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源

### 死锁检测方法

#### 一个资源

检测资源分配图里是否有环

#### 多个资源

银行家算法不能避免的情况就是死锁

### 死锁恢复

1. 抢占恢复
2. 回滚恢复
3. 杀死进程恢复

### 死锁预防

1. 破坏互斥条件：允许多个进程同时使用资源
2. 破坏占有并等待条件：规定进程在开始执行前请求所需要的全部资源
3. 破坏非抢占条件：抢占式！
4. 破坏环路等待：给资源统一编号，进程只能按编号顺序来请求资源

### 死锁避免

银行家算法：由已分配矩阵、需求矩阵、剩余资源向量组成

先给能满足需求的满足了，让其返还已分配资源，如果到最后仍然有进程无法执行，说明死锁；否则死锁避免

## 内存管理

### 虚拟内存

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

**优势在于：可以在有限的内存空间运行大的程序**

基于局部性原理进行设计：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

### 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

#### 什么是虚拟地址

虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

#### 使用虚拟地址的优势

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

### 页面置换算法

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

#### OPT：最佳置换

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

**理论算法，不知道哪个页面多长时间不被访问**

#### LRU：最久未使用

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

#### NRU：最近未使用

NRU 优先换出已经被修改的脏页面

#### FIFO：先进先出

选择换出的页面是最先进入的页面。

### 段/页

虚拟内存采用分页技术，**将地址空间划分成固定大小的页，每一页再与内存进行映射**

但是实际上并不会长时间使用一定大小的内存，而是动态变化的。

#### 分段

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

#### 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

#### 段 vs 页

1. 共同点
	1. 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
	2. 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. 不同点：
	1. 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
	2. 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

各有千秋，物尽其用

## 设备管理

> 主要是磁盘相关的内容

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

### 磁盘调度算法

#### FCFS：先来先服务

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

#### SSTF：最短寻道时间优先

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

#### SCAN：电梯算法

电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。
